{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c541a020",
   "metadata": {
    "id": "c541a020"
   },
   "source": [
    "# Converting netCDF to CSV format\n",
    "### Objective:\n",
    "- netCDF files are large size and can take much more resource to compute for data analysis\n",
    "- Filtering the netCDF file to extract only required attributes/features: \n",
    "    * sounding_id => DateTime\n",
    "    * Xco2 => XCO2 ppm\n",
    "    * Latitude, Longitude => coordinates\n",
    "    * xco2_quality_flag => ( 0 =>good quality, 1 => bad quality)\n",
    "- Convert netCDF to CSV format to reduce the size of data\n",
    "\n",
    "\n",
    "### STEPS: \n",
    "* EXPLORE the Files from all directories and CONCATENATE as a single path\n",
    "* Collect the files paths from different directories\n",
    "* final output: csv files format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a680156",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1652679167658,
     "user": {
      "displayName": "Kikipessa Doll",
      "userId": "16203075636725704864"
     },
     "user_tz": 420
    },
    "id": "9a680156"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import os\n",
    "import netCDF4 as nc\n",
    "\n",
    "# converting the datetime format\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab238c96",
   "metadata": {
    "id": "ab238c96"
   },
   "source": [
    "## Path to NETCDF files\n",
    "- Locate the downloaded netcdf files directory in pc directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fa1e6c8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "executionInfo": {
     "elapsed": 214,
     "status": "error",
     "timestamp": 1652679503238,
     "user": {
      "displayName": "Kikipessa Doll",
      "userId": "16203075636725704864"
     },
     "user_tz": 420
    },
    "id": "1fa1e6c8",
    "outputId": "7e95debd-55c7-47b2-e114-2120a08c6304"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9de3526be9aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Collect the paths of each individual files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfile_names\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmultiple_netcdf_files\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'multiple_netcdf_files' is not defined"
     ]
    }
   ],
   "source": [
    "path_a= ('multiple_netcdf_files/')\n",
    "\n",
    "# Collect the paths of each individual files\n",
    "file_names= [multiple_netcdf_files]\n",
    "\n",
    "for file in os.listdir(path_a):\n",
    "    # Check whether file is in text format or not\n",
    "    if file.endswith(\".nc4\"):\n",
    "        file_path = f\"{path_a}\\{file}\"\n",
    "      \n",
    "        # Store the path location of each individual files\n",
    "        file_names.append(file_path)\n",
    "        \n",
    "        \n",
    "# check first 10 files path\n",
    "file_names[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004626ef",
   "metadata": {
    "id": "004626ef"
   },
   "source": [
    "## If netCDF files are located on different directory paths:\n",
    "### NOTE: Select the Root PATH for files on different folders\n",
    "- Run this script below if the individual files are located in seperate folders\n",
    "- How it works: \n",
    "    - 1. Provide the root direcory\n",
    "    - 2. Loop searches individual files at end paths of each directories\n",
    "    - 3. Concatenates the path from ROOT dir. to individual file path from each dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ced6be4",
   "metadata": {
    "id": "5ced6be4"
   },
   "outputs": [],
   "source": [
    "# # list fo FILES 2021\n",
    "# file_path_2021= []\n",
    "\n",
    "# for root, dirs, files in os.walk('../../../Clusters_DATA_oil/OCO-2/2018/'):\n",
    "#     for filename in files:\n",
    "#         print(os.path.join(root, filename))\n",
    "        \n",
    "#         # Append the files into list\n",
    "#         file_path_2021.append(os.path.join(root, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d457322a",
   "metadata": {
    "id": "d457322a"
   },
   "outputs": [],
   "source": [
    "#files= os.listdir('../ENTIRE_datasets/OCO-2_datasets/2019_2020/')\n",
    "\n",
    "# files= os.listdir('')\n",
    "# # LISTING the path of FILES\n",
    "# files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a27bf7",
   "metadata": {
    "id": "e4a27bf7"
   },
   "source": [
    "# Example: \n",
    "### Opening a single file in netCDF format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c5c0f8",
   "metadata": {
    "id": "71c5c0f8"
   },
   "outputs": [],
   "source": [
    "df_xco2= nc.Dataset('multiple_netcdf_files/oco2_LtCO2_190101_B10206Ar_200729172616s.nc4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf971e06",
   "metadata": {
    "id": "cf971e06",
    "outputId": "10af2033-b003-4841-d57c-cc5db550fcb7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sounding_id',\n",
       " 'levels',\n",
       " 'bands',\n",
       " 'vertices',\n",
       " 'footprints',\n",
       " 'date',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'time',\n",
       " 'solar_zenith_angle',\n",
       " 'sensor_zenith_angle',\n",
       " 'xco2_quality_flag',\n",
       " 'xco2_qf_bitflag',\n",
       " 'xco2_qf_simple_bitflag',\n",
       " 'source_files',\n",
       " 'file_index',\n",
       " 'vertex_latitude',\n",
       " 'vertex_longitude',\n",
       " 'xco2',\n",
       " 'xco2_uncertainty',\n",
       " 'xco2_apriori',\n",
       " 'pressure_levels',\n",
       " 'co2_profile_apriori',\n",
       " 'xco2_averaging_kernel',\n",
       " 'pressure_weight']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_xco2.variables.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5539e984",
   "metadata": {
    "id": "5539e984"
   },
   "source": [
    "### Filtering specific attributes from the netCDF files\n",
    "- xco2\n",
    "- xco2_quality_flag\n",
    "- latitude\n",
    "- longitude\n",
    "- sounding_id (DateTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a107b29",
   "metadata": {
    "id": "4a107b29"
   },
   "source": [
    "***********************************************************************************************\n",
    "***********************************************************************************************\n",
    "***********************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1aa9ba",
   "metadata": {
    "id": "8f1aa9ba"
   },
   "source": [
    "# DateTime format Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4133c955",
   "metadata": {
    "id": "4133c955"
   },
   "outputs": [],
   "source": [
    "# DATE time function\n",
    "def conv_date(d):\n",
    "    return datetime.strptime(str(d), '%Y%m%d%H%M%S%f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2ad694",
   "metadata": {
    "id": "cd2ad694"
   },
   "source": [
    "# Check the total files in the DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de96547b",
   "metadata": {
    "id": "de96547b",
    "outputId": "2c929c0a-183e-447c-d3cb-2bdb0dba76ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TotalFiles:  9\n"
     ]
    }
   ],
   "source": [
    "countFiles=0\n",
    "\n",
    "for j in file_names:\n",
    "    if j.endswith(\".nc4\"):\n",
    "        countFiles+=1\n",
    "        #print(j)\n",
    "        \n",
    "print('\\nTotalFiles: ', countFiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b752b4",
   "metadata": {
    "id": "a9b752b4"
   },
   "source": [
    "### Function:\n",
    "* Function below takes individual path of files and converts to CSV/TXT format\n",
    "* Converted files are created on the same dir. of the code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa6486c",
   "metadata": {
    "id": "efa6486c"
   },
   "source": [
    "# Storing the files on specified directory: csv_files folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbdf3b9",
   "metadata": {
    "id": "5dbdf3b9"
   },
   "outputs": [],
   "source": [
    "#creatin g a FOLDER\n",
    "current_directory= os.getcwd()\n",
    "frames_folder= os.path.join(current_directory, r'csv_files')\n",
    "\n",
    "if not os.path.exists(frames_folder):\n",
    "    os.makedirs(frames_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d135ca",
   "metadata": {
    "id": "d7d135ca"
   },
   "source": [
    "### NOTE:\n",
    "- Refine the ENTIRE dataframe by GOOD quality_flag->0\n",
    "- NOTE: REDUCES the size of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfa8617",
   "metadata": {
    "id": "5bfa8617"
   },
   "outputs": [],
   "source": [
    "# FUNCTION to convert data\n",
    "\n",
    "def convHdf(path_file, n=0):\n",
    "\n",
    "    data= nc.Dataset(path_file)\n",
    "\n",
    "    # get the HDF data and convert to CSV\n",
    "    df_xco2= pd.DataFrame()\n",
    "\n",
    "    df_xco2['Xco2']= data.variables['xco2'][:]\n",
    "    df_xco2['Latitude']= data.variables['latitude'][:]\n",
    "    df_xco2['Longitude']= data.variables['longitude'][:] \n",
    "    df_xco2['quality_flag']= data.variables['xco2_quality_flag'][:] \n",
    "    \n",
    "    # Date\n",
    "    df_xco2['DateTime']= data.variables['sounding_id'][:]\n",
    "    \n",
    "    #Convert soundingID to datetime format\n",
    "    df_xco2['DateTime']= df_xco2['DateTime'].apply(conv_date)\n",
    "    df_xco2['DateTime']= pd.to_datetime(df_xco2['DateTime'])\n",
    "    \n",
    "    # YEAR and month column\n",
    "    df_xco2['Year']= df_xco2['DateTime'].dt.year\n",
    "    df_xco2['Month']= df_xco2['DateTime'].dt.month\n",
    "    df_xco2['Day']= df_xco2['DateTime'].dt.day\n",
    "    \n",
    "    # Refine the ENTIRE dataframe by GOOD quality_flag->0\n",
    "    # NOTE: REDUCES the size of the file\n",
    "    df_xco2= df_xco2[df_xco2['quality_flag'] == 0]   \n",
    "    \n",
    "   \n",
    "    date= str(data.variables['sounding_id'][0])      \n",
    "    \n",
    "    # create a CSV and store on new folder: csv_files\n",
    "    df_xco2.to_csv('csv_files'+'/'+ data.Sensor+'_xco2_'+ date+'_.txt', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7140ef72",
   "metadata": {
    "id": "7140ef72"
   },
   "source": [
    "# OCO3 for SIF conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbfabb7",
   "metadata": {
    "id": "fbbfabb7"
   },
   "outputs": [],
   "source": [
    "# # FUNCTION to convert data\n",
    "# def convOCO3(path_file, n=0):\n",
    "\n",
    "#     #path= '../hdf_format/Los_angeles_GROUPED/'\n",
    "#     data= nc.Dataset(path_file)\n",
    "\n",
    "#     # get the HDF data and convert to CSV\n",
    "#     df_sif= pd.DataFrame()\n",
    "\n",
    "#     df_sif['sif_757nm']= data.variables['Daily_SIF_757nm'][:]\n",
    "#     df_sif['Latitude']= data.variables['Latitude'][:]\n",
    "#     df_sif['Longitude']= data.variables['Longitude'][:] \n",
    "#     df_sif['quality_flag']= data.variables['Quality_Flag'][:] \n",
    "    \n",
    "#     # Date\n",
    "#     # Date time not found \n",
    "# #     df_xco2['DateTime']= data.variables['sounding_id'][:]\n",
    "    \n",
    "# #     #Convert soundingID to datetime format\n",
    "# #     df_xco2['DateTime']= df_xco2['DateTime'].apply(conv_date)\n",
    "# #     df_xco2['DateTime']= pd.to_datetime(df_xco2['DateTime'])\n",
    "    \n",
    "# #     # YEAR and month column\n",
    "# #     df_xco2['Year']= df_xco2['DateTime'].dt.year\n",
    "# #     df_xco2['Month']= df_xco2['DateTime'].dt.month\n",
    "# #     df_xco2['Day']= df_xco2['DateTime'].dt.day\n",
    "    \n",
    "    \n",
    "#     # xco2 quality flag -> 0\n",
    "#  #   df_sif= df_sif[df_sif['quality_flag'] == 0]\n",
    "    \n",
    "# #    date= str(data.variables['sounding_id'][0])                                   \n",
    "#     # create a CSV\n",
    "#     # OCO3 sensor\n",
    "#     df_sif.to_csv(data.sensor[:5]+'_sif_'+str(n)+ '_.txt', index= False)\n",
    "# #     df_xco2.to_feather(data.Sensor+'_xco2_'+ date+'_.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1506ef2f",
   "metadata": {
    "id": "1506ef2f"
   },
   "source": [
    "# Testing: Single files transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be0ec39",
   "metadata": {
    "id": "6be0ec39"
   },
   "outputs": [],
   "source": [
    "convHdf(file_names[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c367997",
   "metadata": {
    "id": "4c367997"
   },
   "source": [
    "## NOTE: Filtering XCO2 quality flag(0) to reduce the total size of file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221c73b6",
   "metadata": {
    "id": "221c73b6"
   },
   "outputs": [],
   "source": [
    "# using Function to READ FILES from the direcotry and convert all netCDF files to csv/txt    \n",
    "\n",
    "for j in range(0, len(file_names)):\n",
    "  \n",
    "       # EG to read FIRST dataset from THE DIRECTORY       \n",
    "        convHdf(file_names[j], j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d89d124",
   "metadata": {
    "id": "8d89d124"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194416c5",
   "metadata": {
    "id": "194416c5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Conversion_NETCDF_to_CSV_2019_2020.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
